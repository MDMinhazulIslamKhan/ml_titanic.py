{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90538dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('./titanic/test.csv')\n",
    "train = pd.read_csv('./titanic/train.csv')\n",
    "\n",
    "train_test_data = [train, test]\n",
    "\n",
    "# # create Title column from Name #\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(r'([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# # set numeric value in Title field #\n",
    "title_mapping = {\n",
    "    \"Mr\" : 0,\n",
    "    \"Miss\" : 1,\n",
    "    \"Mrs\" : 2,\n",
    "    \"Master\" : 3,\n",
    "    \"Dr\" : 3,\n",
    "    \"Rev\" : 3,\n",
    "    \"Col\" : 3,\n",
    "    \"Major\" : 3,\n",
    "    \"Mlle\" : 3,\n",
    "    \"Countess\" : 3,\n",
    "    \"Ms\" : 3,\n",
    "    \"Lady\" : 3,\n",
    "    \"Jonkheer\" : 3,\n",
    "    \"Don\" : 3,\n",
    "    \"Dona\" : 3,\n",
    "    \"Mme\" : 3,\n",
    "    \"Capt\" : 3,\n",
    "    \"Sir\" : 3,\n",
    "}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset[\"Title\"].map(title_mapping)\n",
    "\n",
    "\n",
    "\n",
    "sex_mapping = {\n",
    "    \"male\" : 0,\n",
    "    \"female\" : 1,\n",
    "}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset[\"Sex\"].map(sex_mapping)\n",
    "\n",
    "\n",
    "# # fill missing age with median #\n",
    "train['Age'] = train['Age'].fillna(train.groupby('Title')['Age'].transform('median'))\n",
    "test['Age'] = test['Age'].fillna(test.groupby('Title')['Age'].transform('median'))\n",
    "\n",
    "# # set numeric value in Age field #\n",
    "for dataset in train_test_data:\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 62, 'Age'] = 4\n",
    "\n",
    "# # Most passengers embarked from S, so fill missing data with s #\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "\n",
    "embarked_mapping = {\n",
    "    \"S\" : 0,\n",
    "    \"C\" : 1,\n",
    "    \"Q\" : 2,\n",
    "}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset[\"Embarked\"].map(embarked_mapping)\n",
    "\n",
    "# # Missing Fare fill with median #\n",
    "train['Fare'] = train['Fare'].fillna(train.groupby('Pclass')['Fare'].transform('median'))\n",
    "test['Fare'] = test['Fare'].fillna(test.groupby('Pclass')['Fare'].transform('median'))\n",
    "\n",
    "# # Fare classification #\n",
    "for dataset in train_test_data:\n",
    "    dataset.loc[dataset['Fare'] <= 17, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 100, 'Fare'] = 3\n",
    "\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].str[:1]\n",
    "\n",
    "cabin_mapping = {\n",
    "    \"A\" : 0,\n",
    "    \"B\" : 0.4,\n",
    "    \"C\" : 0.8,\n",
    "    \"D\" : 1.2,\n",
    "    \"E\" : 1.6,\n",
    "    \"F\" : 2.0,\n",
    "    \"G\" : 2.4,\n",
    "    \"T\" : 2.8,\n",
    "}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset[\"Cabin\"].map(cabin_mapping)\n",
    "\n",
    "train['Cabin'] = train['Cabin'].fillna(train.groupby('Pclass')['Cabin'].transform('median'))\n",
    "test['Cabin'] = test['Cabin'].fillna(test.groupby('Pclass')['Cabin'].transform('median'))\n",
    "\n",
    "# # create new column FamilySize #\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "family_size_mapping = {\n",
    "    1: 0.0, \n",
    "    2: 0.4,\n",
    "    3: 0.8,\n",
    "    4: 1.2,\n",
    "    5: 1.6,\n",
    "    6: 2.0,\n",
    "    7: 2.4,\n",
    "    8: 2.8,\n",
    "    9: 3.2,\n",
    "    10: 3.6,\n",
    "    11: 4\n",
    "}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize'] = dataset['FamilySize'].map(family_size_mapping)\n",
    "\n",
    "# # delete unnecessary feature from dataset #\n",
    "feature_drop = ['Ticket', 'SibSp', 'Parch', 'Name']\n",
    "train.drop(feature_drop ,axis=1, inplace=True)\n",
    "test.drop(feature_drop ,axis=1, inplace=True)\n",
    "train.drop('PassengerId' ,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e02121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# # importing classifier module #\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # KFold for cross-validation #\n",
    "from sklearn.model_selection import KFold\n",
    "# # to evaluate model accuracy across multiple data splits #\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# # Creates a 10-fold cross-validator, shuffling data before splitting, random_state=0 ensures reproducibility #\n",
    "K_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "# # Performs 10-fold cross-validation, scoring='accuracy': accuracy is used as the performance metric, n_jobs=1: runs on a single CPU core #\n",
    "score = cross_val_score(clf, X, y, cv=K_fold, n_jobs=1, scoring='accuracy')\n",
    "# print(score)\n",
    "\n",
    "# # decision tree score, prints the average accuracy across all 10 folds #\n",
    "print(round(np.mean(score)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb33e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Final Model with Random Forest, creates a Random Forest model with 13 trees #\n",
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "\n",
    "# # Trains the Random Forest model on the entire training set #\n",
    "clf.fit(X,y)\n",
    "\n",
    "# # Removes PassengerId because it's not a feature #\n",
    "test_data = test.drop('PassengerId', axis=1).copy()\n",
    "# # Predict on Test Set #\n",
    "prediction = clf.predict(test_data)\n",
    "\n",
    "# # Create Submission File #\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\":test['PassengerId'],\n",
    "    \"Survived\":prediction\n",
    "})\n",
    "\n",
    "submission.to_csv('titanic/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
